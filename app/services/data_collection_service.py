# app/services/data_collection_service.py
import asyncio
import logging
import os
import json
from typing import Dict, Any, List, Optional, Union
from pathlib import Path

from app.config.mpstats_ui_config import MPSTATS_UI_CONFIG
from app.services.mpstats_scraper_service import MPStatsScraperService
from app.utils.keywords_processor import KeywordsProcessor


class DataCollectionService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Å–±–æ—Ä–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å MPStats"""

    def __init__(self, config, scraper_service: MPStatsScraperService):
        self.config = config
        self.scraper = scraper_service
        self.logger = logging.getLogger(__name__)
        self.keywords_processor = KeywordsProcessor(
            preserve_excel=False,
            target_column="–ö–ª–∞—Å—Ç–µ—Ä WB"
        )

        # –ü—É—Ç–∏
        self.downloads_dir = Path(config.paths.mpstats_downloads_dir)
        self.keywords_dir = Path(config.paths.keywords_dir)

    async def collect_keywords_data(
            self,
            category: str,
            purpose: Union[str, List[str]] = "",
            additional_params: List[str] = None
    ) -> Dict[str, Any]:
        """
        –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:
        1. –°–∫—Ä–∞–ø–∏–Ω–≥ MPStats
        2. –°–∫–∞—á–∏–≤–∞–Ω–∏–µ Excel
        3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤ JSON
        4. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

        Args:
            category: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            purpose: –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ (—Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ –º–∞—Å—Å–∏–≤ —Å—Ç—Ä–æ–∫)
            additional_params: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        """
        try:
            self.logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞—é —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {category}")

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º purpose: –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –º–∞—Å—Å–∏–≤ —Å—Ç—Ä–æ–∫
            purposes_list = self._normalize_purpose(purpose)

            self.logger.info(f"üéØ –ù–∞–∑–Ω–∞—á–µ–Ω–∏—è: {purposes_list}")

            # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            params = {
                "category": category,
                "purposes": purposes_list,  # –ü–µ—Ä–µ–¥–∞–µ–º –∫–∞–∫ –º–∞—Å—Å–∏–≤
                "additional_params": additional_params or []
            }

            # 2. –ó–∞–ø—É—Å–∫ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞ –∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è Excel
            self.logger.info("üîç –ó–∞–ø—É—Å–∫ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞ MPStats...")
            excel_file = await self._run_scraping_and_download(params)

            if not excel_file:
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª —Å MPStats")

            self.logger.info(f"‚úÖ –§–∞–π–ª —Å–∫–∞—á–∞–Ω: {excel_file}")

            # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ Excel –≤ JSON
            self.logger.info("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ Excel —Ñ–∞–π–ª–∞...")
            result = await self._process_excel_file(
                excel_path=excel_file,
                category=category,
                purposes=purposes_list,
                additional_params=additional_params or []
            )

            # 4. –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            await self._cleanup_temp_files(excel_file)

            self.logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ–±—Ä–∞–Ω—ã. –ö–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {len(result.get('keywords', []))}")

            return {
                "status": "success",
                "category": category,
                "purposes": purposes_list,  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –º–∞—Å—Å–∏–≤
                "additional_params": additional_params or [],
                "keywords": result.get("keywords", []),
                "keywords_preview": result.get("keywords", [])[:15]
            }

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: {e}", exc_info=True)
            return {
                "status": "error",
                "message": str(e),
                "category": category,
                "purposes": self._normalize_purpose(purpose),
                "additional_params": additional_params or [],
                "keywords": [],
                "keywords_preview": []
            }

    def _normalize_purpose(self, purpose: Union[str, List[str], None]) -> List[str]:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç purpose –≤ –º–∞—Å—Å–∏–≤ —Å—Ç—Ä–æ–∫

        Args:
            purpose: –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ (—Å—Ç—Ä–æ–∫–∞, –º–∞—Å—Å–∏–≤ –∏–ª–∏ None)

        Returns:
            –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –º–∞—Å—Å–∏–≤ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–π
        """
        if not purpose:
            return []

        if isinstance(purpose, list):
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            return [str(p).strip() for p in purpose if str(p).strip()]
        elif isinstance(purpose, str):
            # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏, —Ä–∞–∑–±–∏–≤–∞–µ–º
            if "," in purpose:
                return [p.strip() for p in purpose.split(",") if p.strip()]
            else:
                return [purpose.strip()] if purpose.strip() else []
        else:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É
            return [str(purpose).strip()]

    async def _run_scraping_and_download(self, params: Dict[str, Any]) -> str:
        """–ó–∞–ø—É—Å–∫ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞ –∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è Excel —Ñ–∞–π–ª–∞"""
        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∫—Ä–∞–ø–µ—Ä–∞
            await self.scraper.initialize_scraper()

            # –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å MPStatsScraperService
            # –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –º–∞—Å—Å–∏–≤ purposes –≤ —Å—Ç—Ä–æ–∫—É
            scraper_params = params.copy()
            if "purposes" in scraper_params:
                purposes_list = scraper_params["purposes"]
                if isinstance(purposes_list, list) and purposes_list:
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤ —Å—Ç—Ä–æ–∫—É –¥–ª—è scraper_service
                    scraper_params["purpose"] = ", ".join(purposes_list)
                elif purposes_list:
                    scraper_params["purpose"] = str(purposes_list)

            # –ó–∞–ø—É—Å–∫ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞
            result = await self.scraper.scrape_categories(scraper_params)

            if result.get("status") != "success":
                raise Exception(f"–û—à–∏–±–∫–∞ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞: {result.get('message')}")

            driver = result.get("driver")

            if not driver:
                raise Exception("–î—Ä–∞–π–≤–µ—Ä –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

            # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
            excel_file = await self.scraper.download_keywords_data(driver, scraper_params)

            return excel_file

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
            raise

    async def _process_excel_file(
            self,
            excel_path: str,
            category: str,
            purposes: List[str],
            additional_params: List[str]
    ) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ Excel —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ KeywordsProcessor"""
        try:
            # –°–æ–∑–¥–∞–µ–º –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–π JSON
            json_path = self.keywords_processor.create_enriched_json(
                excel_path=excel_path,
                category=category,
                purpose=", ".join(purposes) if purposes else "",  # –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                additional_params=additional_params,
                json_path=str(
                    self.keywords_dir / f"{category}_{'_'.join(purposes[:2]) if purposes else 'all'}_enriched.json")
            )

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # –û–±–æ–≥–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ purposes (–º–∞—Å—Å–∏–≤–æ–º)
            data["purposes"] = purposes
            data["purpose"] = ", ".join(purposes) if purposes else ""  # –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            return data

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ Excel —Ñ–∞–π–ª–∞: {e}")
            raise

    async def _cleanup_temp_files(self, excel_file: str):
        """–û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        try:
            if os.path.exists(excel_file):
                os.remove(excel_file)
                self.logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {excel_file}")
        except Exception as e:
            self.logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª {excel_file}: {e}")